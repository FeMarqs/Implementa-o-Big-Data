# -*- coding: utf-8 -*-
"""kart_pyspark_jean.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CW2nRO5SV8eQQ_qbLvETf1vSJj2ZR0hg
"""

pip install pyspark

import random
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
spark = SparkSession.builder \
                .appName('SparkByExamples.com')\
                .getOrCreate()

data = [("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),
        ("volta_1", random.randint(60,90), random.randint(58,90), random.randint(60,90), random.randint(60,90), random.randint(60,90), random.randint(60,90)),]

colums = ["Voltas", "Robert", "Pedro", "Rian", "Renan", "Bruce", "Romulo"]
df = spark.createDataFrame(data = data, schema = colums)
df.show()
data_novo = [("Robert", df.agg({'Robert' : 'sum'}).collect()[0][0]),
             ("Pedro", df.agg({'Pedro' : 'sum'}).collect()[0][0]),
             ("Rian", df.agg({'Rian' : 'sum'}).collect()[0][0]),
             ("Renan", df.agg({'Renan' : 'sum'}).collect()[0][0]),
             ("Bruce", df.agg({'Bruce' : 'sum'}).collect()[0][0]),
             ("Romulo", df.agg({'Romulo' : 'sum'}).collect()[0][0])]
nova_coluna = ["nome", "resultado"]

df3 = spark.createDataFrame(data_novo, nova_coluna)
valor_campeao = df3.orderBy(['resultado'], ascending = [True]).colet()[0][1]
campeao = df3.orderBy(['resultado'], ascending = [True]).collect()[0][0]
print("O campeão fez: ", valor_campeao , " segundos, e seu nome é : ", campeao)
print("A classificação foi : ")
df3.orderBy(['resultado'], ascending = [True]).show